\documentclass[24pt,pdf,hyperref={unicode}]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{graphics}
\usepackage{amssymb}
\usepackage{xstring}
\usepackage{multirow}
\usepackage[all]{xy}


\newcommand{\dd}[2]{\frac{\partial #1}{\partial #2}}
\begin{document}

\section{Персептрон}

\begin{frame}\frametitle{Персептрон}
\begin{columns}
\column{0.5\textwidth}
$$
\xymatrix
{
x_1 \ar@{->}[rd]^{w_1} \\
x_2 \ar@{->}[r]^{w_2} & *++[Fo]{f} \ar@{->}[r] & y\\
x_3 \ar@{->}[ru]_{w_3} \\
}
$$
\column{0.5\textwidth}
$$
y=f\left(\sum_{i=1}^{n}w_ix_i\right)
$$\\[1cm]
$$
f(x)={\rm sign}(x)
$$
\end{columns}
\end{frame}


\begin{frame}\frametitle{Вес активации}
\begin{columns}
\column{0.5\textwidth}
$$
\xymatrix
{
x_1 \ar@{->}[rd]^{w_1} \\
x_2 \ar@{->}[r]^{w_2} & *++[Fo]{f} \ar@{->}[r] & y\\
x_3 \ar@{->}[ru]_{w_3} \\
}
$$
\column{0.5\textwidth}
$$
\xymatrix
{
x_1 \ar@{->}[rd]^{w_1} & x_0\equiv 1 \ar@{->}[d]^{w_0}\\
x_2 \ar@{->}[r]^{w_2} & *++[Fo]{f} \ar@{->}[r] & y\\
x_3 \ar@{->}[ru]_{w_3} \\
}
$$
\end{columns}
\end{frame}

\begin{frame}\frametitle{Реализация конъюнкции}
\begin{columns}
\column{0.5\textwidth}
$$
\begin{array}{c c | c}
x_1 & x_2 & x_1\wedge x_2 \\
\hline
0 & 0 & 0 \\
0 & 1 & 0 \\
1 & 0 & 0 \\
1 & 1 & 1 \\
\end{array}
$$
\column{0.5\textwidth}
$$
\left\{
\begin{array}{l l l l l l}
 w_0       & < & 0 \\
 w_0 + w_1 & < & 0 \\
 w_0 + w_2 & < & 0 \\
 w_0 + w_1 + w_2 & > & 0 \\
\end{array}
\right.
$$\\[1cm]
\uncover<2>{
$$
\begin{array}{l}
 w_0 = 3 \\
 w_1 = 2 \\
 w_2 = 2 \\
\end{array}
$$
}
\end{columns}
\end{frame}


\begin{frame}\frametitle{Реализация дизъюнкции}
\begin{columns}
\column{0.5\textwidth}
$$
\begin{array}{c c | c}
x_1 & x_2 & x_1\vee x_2 \\
\hline
0 & 0 & 0 \\
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 1 \\
\end{array}
$$
\column{0.5\textwidth}
$$
\left\{
\begin{array}{l l l l l l}
 w_0       & < & 0 \\
 w_0 + w_1 & > & 0 \\
 w_0 + w_2 & > & 0 \\
 w_0 + w_1 + w_2 & > & 0 \\
\end{array}
\right.
$$\\[1cm]
$$
\begin{array}{l}
 w_0 = 1 \\
 w_1 = 2 \\
 w_2 = 2 \\
\end{array}
$$
\end{columns}
\end{frame}

\begin{frame}\frametitle{Геометрическая интерпретация}
в PP
\end{frame}

\begin{frame}\frametitle{Обучение персептрона}
Тут про советчиков, м.б. тоже в PP
\end{frame}

\section{Обратное распространение ошибки}
\begin{frame}\frametitle{Частные производные}
Функция $n$ переменных:
$$
F:\mathbb{R}^n\rightarrow\mathbb{R} 
$$
$$
F(x_1,\ldots,x_n)
$$
Частная производная по $i$-й переменной:
$$
\dd{F}{x_i}=\lim_{\varepsilon\rightarrow 0}\frac{F(x_1,x_2,\ldots,x_i+\varepsilon,\ldots,x_n)-F(x_1,x_2,\ldots,x_i,\ldots,x_n)}{\varepsilon}
$$
\end{frame}

\begin{frame}\frametitle{Частные производные}
$$
F(x,y,z)=x^3+x^y+\sin(yz)
$$
$$
\dd{F}{x}=\uncover<2>{3x^2+yx^{y-1}}
$$
\end{frame}


% \begin{frame}\frametitle{Основные определения}
% \begin{tabular}{l l}
%  $\mathcal{I}=(I_1,\ldots,I_k)$ & входные вектора размерности $n$\\
%  $\mathcal{A}=(A_1,\ldots,A_k)$ & правильные выходные вектора размерности $m$\\
%  $(\mathcal{I},\mathcal{A})$ & обучающая выборка 
%  $N(I_i):\mathbb{R}^n\rightarrow\mathbb{R}^m$ & функция, соответствующая нейронной сети \\
%  $O_i=N(I_i) $ & ответ нейронной сети размерности $n$ \\
% \end{tabular}\\[2cm]
% 
% Функция ошибки:
% $$
% E(O_i,A_i)=\sum_{j=1}^{m} (O_i[j]-A_i[j])^2
% $$
% 
% 
% \end{frame}
% 
% 
% 




\end{document}